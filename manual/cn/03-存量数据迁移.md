# 存量数据迁移

##快速上手

1. 新建配置
   
   ```yaml
   level: "info"
   elastics:
       source-es5:
           addresses:
               - "http://192.168.1.55:9200"
               - "http://192.168.1.56:9200"
               - "http://192.168.1.56:9200"
           user: "es-user"
           password: "123456"
       source-es8:
           addresses:
               - "http://192.168.1.67:9200"
               - "http://192.168.1.68:9200"
               - "http://192.168.1.69:9200"
           user: "es-user2"
           password: "123456"
   
   tasks:
     - name: stock-sync-task
       source_es: es5
       target_es: es8
       index_pairs:
         -
           source_index: "hello_sample"
           target_index: "sample_123"
       index_pattern: "test_.*"
       force: true
       slice_size: 5
       scroll_size: 5000
       buffer_count: 3000
       action_parallelism: 5
       action_size: 5
       scroll_time: 10
       parallelism: 12
       query: '{"terms": {"_id": ["1", "2", "3"]}}'
       action: sync
   ```

2. 执行命令进行数据同步
   
   ```bash
   ./ela --config ./config.yaml --task stock-sync-task
   ```

## 功能详解

### 配置

配置存量数据迁移的任务

| 配置路径                                  | 备注                                                                                                              |
|---------------------------------------|-----------------------------------------------------------------------------------------------------------------|
| /tasks/{task-name}                    | 任务名称，用户可以定义多个不同的任务，不同任务的执行是顺序的。                                                                                 |
| /tasks/{task-name}/source_es          | 数据迁移的源 ES                                                                                                       |
| /tasks/{task-name}/target_es          | 数据迁移的目标 ES                                                                                                      |
| /tasks/{task-name}/index_pairs        | 数据迁移的索引对, 将源 ES 中的 source_index 迁移到目标 ES 中的 target_index 中。                                                     |
| /tasks/{task-name}/index_pattern      | 提供了正则表达式的方式指定索引对；需要源 ES 中的索引数据迁移到目标 ES 中的相同名称的索引中。                                                              |
| /tasks/{task-name}/force              | 在全量数据同步之前，是否强制删除目标 ES 中的索引，并且拷贝源 ES 中的索引配置拷贝到目标 ES中。如果设置为 False，遇到相同 ID 的索引就会在目标索引中进行 update 操作，覆盖目标 ES 里面索引数据。 |
| /tasks/{task-name}/slice_size         | 为了加快遍历源 ES 中索引数据的速度；分片去遍历数据；分片的数量不适合过大，一般在 20-30 左右；根据源 ES 服务的承受能力而设定。slice_size 决定了并发去查询遍历源 ES 的并发数量。          |
| /tasks/{task-name}/scroll_time        | 遍历数据时，游标有一个有效时间，如果设置太小，会导致游标失效；默认的时间为 10 分钟。                                                                    |
| /tasks/{task-name}/scroll_size        | 遍历数据时，一次请求从源 ES 中获取的数据量。                                                                                        |
| /tasks/{task-name}/buffer_count       | 遍历出来的数据会放入到一个队列中，这个参数用来设置队列的容量；同时这个参数也决定了 ela 工具在本地的内存消耗。                                                       |
| /tasks/{task-name}/action_parallelism | 遍历出来的数据，会批量写入到目标 ES 中；用该参数来确定写的并发数量。                                                                            |
| /tasks/{task-name}/action_size        | 该参数的单位为 M; 当拼凑的批量写入接口的 body size 达到后，就会进行一次批量写入操作。                                                              |
| /tasks/{task-name}/parallelism        | 会有很多索引对进行数据同步，该参数用来设置在同一个任务内，有多少个索引对同时在进行并发的进行数据同步。                                                             |
| /tasks/{task-name}/ids                | 该参数不是必须的，主要用于对某个索引的指定document 进行数据同步；该参数应该被设置为 document 的 _id 字段的列表，用空格间隔，例如："abc def cdf"                      |
| /tasks/{task-name}/action             | 设置为 sync，表示会进行存量的数据同步。                                                                                          |
| /tasks/{task-name}/query              | 设置过滤条件，对部分数据进行迁移                                                                                                |

## 总结

在使用 ELA 的工具时，最重要的是需要保证不对现有的业务造成影响；在测试的时候，应该先设置一个比较小的值，保证能够工作起来；然后根据 ES 的服务运行情况，不断的调整参数以达到一个理想的数据迁移速度。
